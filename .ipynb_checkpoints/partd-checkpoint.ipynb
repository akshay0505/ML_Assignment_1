{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "data_dir = os.getcwd()+\"/log_data/\"\n",
    "sys.argv = [\"file\",data_dir+\"train.csv\", data_dir+\"test.csv\", data_dir+\"param_a.txt\" ,data_dir+\"outputfile.csv\", data_dir+\"weightfile.csv\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotencode_train(data):\n",
    "    train = pd.DataFrame()\n",
    "    parents = pd.get_dummies(data[0], prefix=\"parents\")\n",
    "    has_nurs = pd.get_dummies(data[1], prefix=\"has_nurs\")\n",
    "    form = pd.get_dummies(data[2], prefix=\"form\")\n",
    "    children = pd.get_dummies(data[3], prefix=\"children\")\n",
    "    housing = pd.get_dummies(data[4], prefix=\"housing\")\n",
    "    finance = pd.get_dummies(data[5], prefix=\"finance\")\n",
    "    social = pd.get_dummies(data[6], prefix=\"social\")\n",
    "    health = pd.get_dummies(data[7], prefix=\"health\")\n",
    "    classDistribution = pd.get_dummies(data[8], prefix=\"class\")\n",
    "    train = pd.concat([parents, has_nurs, form, children, housing,\n",
    "                    finance, social, health, classDistribution], axis=1)\n",
    "    cols = ['parents_usual', 'parents_pretentious', 'parents_great_pret', 'has_nurs_proper', 'has_nurs_less_proper', 'has_nurs_improper',\n",
    "            'has_nurs_critical', 'has_nurs_very_crit',\n",
    "            'form_complete', 'form_completed', 'form_incomplete', 'form_foster',\n",
    "            'children_1', 'children_2', 'children_3', 'children_more',\n",
    "            'housing_convenient', 'housing_less_conv', 'housing_critical',\n",
    "            'finance_convenient', 'finance_inconv',\n",
    "            'social_nonprob', 'social_slightly_prob', 'social_problematic',\n",
    "            'health_recommended', 'health_priority', 'health_not_recom',\n",
    "            'class_not_recom', 'class_recommend', 'class_very_recom', 'class_priority', 'class_spec_prior']\n",
    "\n",
    "    return train[pd.Index(cols)]\n",
    "\n",
    "def hotencode_test(data):\n",
    "    train = pd.DataFrame()\n",
    "    parents = pd.get_dummies(data[0], prefix=\"parents\")\n",
    "    has_nurs = pd.get_dummies(data[1], prefix=\"has_nurs\")\n",
    "    form = pd.get_dummies(data[2], prefix=\"form\")\n",
    "    children = pd.get_dummies(data[3], prefix=\"children\")\n",
    "    housing = pd.get_dummies(data[4], prefix=\"housing\")\n",
    "    finance = pd.get_dummies(data[5], prefix=\"finance\")\n",
    "    social = pd.get_dummies(data[6], prefix=\"social\")\n",
    "    health = pd.get_dummies(data[7], prefix=\"health\")\n",
    "    train = pd.concat([parents, has_nurs, form, children, housing,\n",
    "                    finance, social, health], axis=1)\n",
    "    cols = ['parents_usual', 'parents_pretentious', 'parents_great_pret', 'has_nurs_proper', 'has_nurs_less_proper', 'has_nurs_improper',\n",
    "            'has_nurs_critical', 'has_nurs_very_crit',\n",
    "            'form_complete', 'form_completed', 'form_incomplete', 'form_foster',\n",
    "            'children_1', 'children_2', 'children_3', 'children_more',\n",
    "            'housing_convenient', 'housing_less_conv', 'housing_critical',\n",
    "            'finance_convenient', 'finance_inconv',\n",
    "            'social_nonprob', 'social_slightly_prob', 'social_problematic',\n",
    "            'health_recommended', 'health_priority', 'health_not_recom']\n",
    "    return train[pd.Index(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 28) (5400, 5) (600, 28)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(sys.argv[1], header=None)\n",
    "test_data = pd.read_csv(sys.argv[2], header=None)\n",
    "train = hotencode_train(train_data)\n",
    "test = hotencode_test(test_data)\n",
    "classes = train.iloc[:, -5:].values\n",
    "features = train.iloc[:, :-5].values\n",
    "features = np.c_[np.ones(len(train)), features]\n",
    "X_train = features[:5400, :]\n",
    "Y_train = classes[:5400, :]\n",
    "X_test = features[5400:, :]\n",
    "Y_test = classes[5400:, :]\n",
    "print(X_train.shape, Y_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X,Y,W):\n",
    "    XW = np.exp(np.matmul(X, W))\n",
    "    denom = np.sum(XW, axis=1)\n",
    "    Y_predict = np.divide(XW, denom.reshape(X.shape[0], 1))\n",
    "    return np.matmul(X.transpose(), Y - Y_predict)/X.shape[0]\n",
    "def cost(W,X,Y):\n",
    "    XW = np.exp(np.matmul(X,W))\n",
    "    logTerm = np.log(np.sum(XW,axis=1))\n",
    "    weightedTerm = np.sum(np.multiply(np.matmul(Y,W.T),X),axis=1)\n",
    "    error = np.sum(logTerm-weightedTerm)/X.shape[0]\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.000005,0.00001,0.00005,0.0001, .001, .01,0.1,1,10]\n",
    "batch = [10,1]\n",
    "a = np.zeros((len(alpha),len(batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1224, 0.546937192788872))\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1b38420bf1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_initial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mw_initial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_initial\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_initial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_initial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcostAr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7fb0c0209e26>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(W, X, Y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mXW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlogTerm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mweightedTerm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogTerm\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweightedTerm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "costOverall = []\n",
    "a=[]\n",
    "for n in range(0,len(alpha)):\n",
    "    w_initial = np.ones(28*5).reshape(28, 5)\n",
    "    w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "    costAr = []\n",
    "    lr = .01\n",
    "    costAr.append(0)\n",
    "    for j in range(1, 10000):\n",
    "        grad = gradient(X_train,Y_train,w_initial)\n",
    "        w_initial = w_initial+lr*(grad-alpha[n]*w_initial)\n",
    "        c = cost(w_initial,X_train,Y_train)\n",
    "        print((j,c), end=\"\\r\", flush=True)\n",
    "        costAr.append(c)\n",
    "        if(costAr[j-1]-costAr[j]<.00001 and j>10):\n",
    "            print(costAr[j],costAr[j-1])\n",
    "            break\n",
    "    WmulX = np.exp(np.matmul(X_test, w_initial))\n",
    "    denom = np.sum(WmulX, axis=1)\n",
    "    Y_predict = np.divide(WmulX, denom.reshape(len(X_test), 1))\n",
    "    b = np.zeros_like(Y_predict)\n",
    "    b[np.arange(len(Y_predict)), Y_predict.argmax(1)] = 1\n",
    "    Y_predict = b\n",
    "    accuracy = np.trace(np.matmul(Y_predict, Y_test.T))/len(X_test)\n",
    "    print(m,accuracy)\n",
    "    a[n]=accuracy        \n",
    "    costOverall.append(costAr)  \n",
    "print(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(0,len(batch)):\n",
    "    for n in range(0,len(alpha)):\n",
    "        w_initial = np.zeros(28*5).reshape(28, 5)\n",
    "        # w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "        costAr = []\n",
    "        k = batch[m]\n",
    "        l = X_train.shape[0]\n",
    "        costAr.append(0)\n",
    "        for j in range(1, 10000):\n",
    "            for i in range(0,k):\n",
    "                grad  = gradient(X_train[int((l/k)*i):int((l/k)*(i+1)),:] , Y_train[int((l/k)*i):int((l/k)*(i+1)),:], w_initial)\n",
    "                w_initial = w_initial+0.01*(grad-alpha[n]*w_initial)\n",
    "                # w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "            c = cost(w_initial,X_train,Y_train)\n",
    "            print((j,c), end=\"\\r\", flush=True)\n",
    "            costAr.append(c)\n",
    "            if(costAr[j-1]-costAr[j]<.00001 and j>10):\n",
    "                print(costAr[j],costAr[j-1])\n",
    "                break\n",
    "        print(j)\n",
    "        w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "        WmulX = np.exp(np.matmul(X_test, w_initial))\n",
    "        denom = np.sum(WmulX, axis=1)\n",
    "        Y_predict = np.divide(WmulX, denom.reshape(len(X_test), 1))\n",
    "        b = np.zeros_like(Y_predict)\n",
    "        b[np.arange(len(Y_predict)), Y_predict.argmax(1)] = 1\n",
    "        Y_predict = b\n",
    "        accuracy = np.trace(np.matmul(Y_predict, Y_test.T))/len(X_test)\n",
    "        print(m,accuracy)\n",
    "        a[n][m]=accuracy\n",
    "print(a)\n",
    "X_train = features[:, :]\n",
    "X_train[:,21]=0\n",
    "Y_train = classes[:, :]\n",
    "print(X_train.shape,Y_train.shape)\n",
    "lamIndex, batchIndex =  np.where(a==np.max(a))[0][0], np.where(a==np.max(a))[1][0]\n",
    "w_initial = np.ones(28*5).reshape(28, 5)\n",
    "w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "costAr = []\n",
    "k = batch[batchIndex]\n",
    "l = X_train.shape[0]\n",
    "costAr.append(0)\n",
    "for j in range(1, 10000):\n",
    "    for i in range(0,k):\n",
    "        grad  = gradient(X_train[int((l/k)*i):int((l/k)*(i+1)),:] , Y_train[int((l/k)*i):int((l/k)*(i+1)),:], w_initial)\n",
    "        w_initial = w_initial+0.01*(grad-alpha[lamIndex]*w_initial)\n",
    "        w_initial = (w_initial.T - w_initial.T[0]).T\n",
    "    c = cost(w_initial,X_train,Y_train)\n",
    "    print((j,c), end=\"\\r\", flush=True)\n",
    "    costAr.append(c)\n",
    "    if(costAr[j-1]-costAr[j]<.00001 and j>10):\n",
    "        print(costAr[j],costAr[j-1])\n",
    "        break\n",
    "print(j)\n",
    "features = test.iloc[:, :].values\n",
    "features = np.c_[np.ones(len(test)), features]\n",
    "X_test = features[:, :]\n",
    "X_test[:,21]=0\n",
    "WmulX = np.exp(np.matmul(X_test, w_initial))\n",
    "denom = np.sum(WmulX, axis=1)\n",
    "Y_predict = np.divide(WmulX, denom.reshape(len(X_test), 1))\n",
    "b = np.zeros_like(Y_predict)\n",
    "b[np.arange(len(Y_predict)), Y_predict.argmax(1)] = 1\n",
    "Y_predict = b\n",
    "Y_predict[:, 0] = 1*Y_predict[:, 0]\n",
    "Y_predict[:, 1] = 2*Y_predict[:, 1]\n",
    "Y_predict[:, 2] = 3*Y_predict[:, 2]\n",
    "Y_predict[:, 3] = 4*Y_predict[:, 3]\n",
    "Y_predict[:, 4] = 5*Y_predict[:, 4]\n",
    "Y_predict = np.sum(Y_predict, axis=1).tolist()\n",
    "predict = []\n",
    "for i in range(0, len(Y_predict)):\n",
    "    if(Y_predict[i] == 1):\n",
    "        predict.append(\"not_recom\")\n",
    "    elif(Y_predict[i] == 2):\n",
    "        predict.append(\"recommend\")\n",
    "    elif(Y_predict[i] == 3):\n",
    "        predict.append(\"very_recom\")\n",
    "    elif(Y_predict[i] == 4):\n",
    "        predict.append(\"priority\")\n",
    "    elif(Y_predict[i] == 5):\n",
    "        predict.append(\"spec_prior\")\n",
    "Y_predict = pd.DataFrame(predict)\n",
    "Y_predict.to_csv(sys.argv[3], header=False, index=False)\n",
    "w_initial = pd.DataFrame(w_initial)\n",
    "w_initial.to_csv(sys.argv[4], header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
