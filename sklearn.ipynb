{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.datasets import load_iris\n",
    "data_dir = os.getcwd()+\"/log_data/\"\n",
    "sys.argv = [\"file\",\"train.csv\", \"test.csv\", \"param_a.txt\" ,\"outputfile.csv\", \"weightfile.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hotencode_train(data):\n",
    "    train = pd.DataFrame()\n",
    "    parents = pd.get_dummies(data[0], prefix=\"parents\")\n",
    "    has_nurs = pd.get_dummies(data[1], prefix=\"has_nurs\")\n",
    "    form = pd.get_dummies(data[2], prefix=\"form\")\n",
    "    children = pd.get_dummies(data[3], prefix=\"children\")\n",
    "    housing = pd.get_dummies(data[4], prefix=\"housing\")\n",
    "    finance = pd.get_dummies(data[5], prefix=\"finance\")\n",
    "    social = pd.get_dummies(data[6], prefix=\"social\")\n",
    "    health = pd.get_dummies(data[7], prefix=\"health\")\n",
    "    classDistribution = pd.get_dummies(data[8], prefix=\"class\")\n",
    "    train = pd.concat([parents, has_nurs, form, children, housing,\n",
    "                    finance, social, health, classDistribution], axis=1)\n",
    "    cols = ['parents_usual', 'parents_pretentious', 'parents_great_pret', 'has_nurs_proper', 'has_nurs_less_proper', 'has_nurs_improper',\n",
    "            'has_nurs_critical', 'has_nurs_very_crit',\n",
    "            'form_complete', 'form_completed', 'form_incomplete', 'form_foster',\n",
    "            'children_1', 'children_2', 'children_3', 'children_more',\n",
    "            'housing_convenient', 'housing_less_conv', 'housing_critical',\n",
    "            'finance_convenient', 'finance_inconv',\n",
    "            'social_nonprob', 'social_slightly_prob', 'social_problematic',\n",
    "            'health_recommended', 'health_priority', 'health_not_recom',\n",
    "            'class_not_recom', 'class_recommend', 'class_very_recom', 'class_priority', 'class_spec_prior']\n",
    "\n",
    "    return train[pd.Index(cols)]\n",
    "\n",
    "def hotencode_test(data):\n",
    "    train = pd.DataFrame()\n",
    "    parents = pd.get_dummies(data[0], prefix=\"parents\")\n",
    "    has_nurs = pd.get_dummies(data[1], prefix=\"has_nurs\")\n",
    "    form = pd.get_dummies(data[2], prefix=\"form\")\n",
    "    children = pd.get_dummies(data[3], prefix=\"children\")\n",
    "    housing = pd.get_dummies(data[4], prefix=\"housing\")\n",
    "    finance = pd.get_dummies(data[5], prefix=\"finance\")\n",
    "    social = pd.get_dummies(data[6], prefix=\"social\")\n",
    "    health = pd.get_dummies(data[7], prefix=\"health\")\n",
    "    train = pd.concat([parents, has_nurs, form, children, housing,\n",
    "                    finance, social, health], axis=1)\n",
    "    cols = ['parents_usual', 'parents_pretentious', 'parents_great_pret', 'has_nurs_proper', 'has_nurs_less_proper', 'has_nurs_improper',\n",
    "            'has_nurs_critical', 'has_nurs_very_crit',\n",
    "            'form_complete', 'form_completed', 'form_incomplete', 'form_foster',\n",
    "            'children_1', 'children_2', 'children_3', 'children_more',\n",
    "            'housing_convenient', 'housing_less_conv', 'housing_critical',\n",
    "            'finance_convenient', 'finance_inconv',\n",
    "            'social_nonprob', 'social_slightly_prob', 'social_problematic',\n",
    "            'health_recommended', 'health_priority', 'health_not_recom']\n",
    "    return train[pd.Index(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(data_dir+sys.argv[1], header=None)\n",
    "# test_data = pd.read_csv(data_dir+sys.argv[2], header=None)\n",
    "train = hotencode_train(train_data)\n",
    "# test = hotencode_test(test_data)\n",
    "classes = np.copy(train.iloc[:, -5:].values)\n",
    "features = np.copy(train.iloc[:, :-5].values)\n",
    "# features = np.c_[np.ones(len(train)), features]\n",
    "\n",
    "# X_train[:,21]=0\n",
    "# features = test.iloc[:, :].values\n",
    "# features = np.c_[np.ones(len(test)), features]\n",
    "# X_test = features[:, :]\n",
    "# X_test[:,21]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 4]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(classes,np.array([0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 27) (6000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = features\n",
    "Y_train = np.sum(np.multiply(classes,np.array([1,2,3,4,5])),axis=1)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,4,28) into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-32f0b1ea77f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2103\u001b[0m             coefs_paths = np.reshape(\n\u001b[1;32m   2104\u001b[0m                 \u001b[0mcoefs_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_ratios_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m             )\n\u001b[1;32m   2107\u001b[0m             \u001b[0;31m# equiv to coefs_paths = np.moveaxis(coefs_paths, (0, 1, 2, 3),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    290\u001b[0m            [5, 6]])\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,4,28) into shape (10)"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5,random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train[:5400,:], Y_train[:5400])\n",
    "Y_pred = clf.predict(X_train[5400:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-83817a3d6d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "Y_train[:5400,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186,   0,   0,   0],\n",
       "       [  0,   9,   6,   0],\n",
       "       [  0,   1, 194,  20],\n",
       "       [  0,   0,  19, 165]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_train[5400:], Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()+\"/data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.437500</td>\n",
       "      <td>75.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>44.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.781250</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.859375</td>\n",
       "      <td>56.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.273438</td>\n",
       "      <td>4.984375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.029297</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.148438</td>\n",
       "      <td>32.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.152344</td>\n",
       "      <td>20.453125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.285156</td>\n",
       "      <td>8.414062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>4.722656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1    2      3     4          5          6    7      8    \\\n",
       "0  43.437500  75.562500  0.0  634.0  20.0  16.000000  44.562500  0.0  473.0   \n",
       "1  47.781250  93.750000  1.0  598.0   7.5  17.859375  56.875000  0.0  594.0   \n",
       "2   2.273438   4.984375  0.0   44.0   1.0   1.029297   3.003906  0.0   37.0   \n",
       "3  10.148438  32.406250  0.0  292.0   0.0   5.152344  20.453125  0.0  220.0   \n",
       "4   2.285156   8.414062  0.0  102.0   1.0   0.973633   4.722656  0.0   93.0   \n",
       "\n",
       "   9    ...  237  238  239  240  241  242  243  244  245   246  \n",
       "0  2.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   1.0  \n",
       "1  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  52.0  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   0.0  \n",
       "3  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   0.0  \n",
       "4  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   0.0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf= pd.read_csv(data_dir,header=None)\n",
    "trainDf[246] = trainDf[245]\n",
    "trainDf[245] = np.ones(30000)\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-125bd7ed0188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 246) (30000,) (5000, 246) (5000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = trainDf.iloc[:,:-1].values\n",
    "Y_train = trainDf.iloc[:,246].values\n",
    "X_test = trainDf.iloc[25000:,:-1].values\n",
    "Y_test = trainDf.iloc[25000:,246].values\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e44e2b5bd9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit  = test.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\") % fit.explained_variance_ratio_\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.array(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09686246402996249"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.009913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.011742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.012137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.013077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.013501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.013261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.007626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.007343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.008004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.008009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.006633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.004670\n",
       "1    0.006477\n",
       "2    0.000750\n",
       "3    0.012223\n",
       "4    0.008678\n",
       "5    0.009707\n",
       "6    0.004113\n",
       "7    0.000336\n",
       "8    0.006183\n",
       "9    0.010618\n",
       "10   0.007632\n",
       "11   0.005874\n",
       "12   0.010163\n",
       "13   0.004063\n",
       "14   0.004896\n",
       "15   0.004249\n",
       "16   0.009913\n",
       "17   0.005203\n",
       "18   0.011318\n",
       "19   0.005512\n",
       "20   0.004759\n",
       "21   0.007597\n",
       "22   0.002207\n",
       "23   0.002238\n",
       "24   0.002760\n",
       "25   0.000023\n",
       "26   0.002400\n",
       "27   0.000964\n",
       "28   0.002233\n",
       "29   0.002885\n",
       "..        ...\n",
       "216  0.006375\n",
       "217  0.000735\n",
       "218  0.000812\n",
       "219  0.000770\n",
       "220  0.000027\n",
       "221  0.001698\n",
       "222  0.001164\n",
       "223  0.000010\n",
       "224  0.002554\n",
       "225  0.000225\n",
       "226  0.000350\n",
       "227  0.000306\n",
       "228  0.000780\n",
       "229  0.000023\n",
       "230  0.011742\n",
       "231  0.011399\n",
       "232  0.012137\n",
       "233  0.013077\n",
       "234  0.013501\n",
       "235  0.013261\n",
       "236  0.007626\n",
       "237  0.007692\n",
       "238  0.007343\n",
       "239  0.008004\n",
       "240  0.008009\n",
       "241  0.006633\n",
       "242  0.004695\n",
       "243  0.001443\n",
       "244  0.001379\n",
       "245  0.000000\n",
       "\n",
       "[246 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(np.flip(np.argsort(score)))\n",
    "df = pd.DataFrame(score)\n",
    "# np.argsort(np.array(model.feature_importances_))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52,  45,  44,  47,  46,  53, 234, 235, 233,   3, 232,  48, 230,\n",
       "        49, 231,  18,  51,   9,  12,  16,   5,   4, 240, 239,  50, 237,\n",
       "        10, 236,  21, 238, 202, 181, 132,  58, 106,  60, 137, 196, 183,\n",
       "       241,   1, 121, 216, 104,   8, 173,  98,  68, 203, 167,  11, 146,\n",
       "        55,  59,  19,  17, 198,  85, 166,  14, 164, 215,  20, 125, 242,\n",
       "         0, 200, 138, 154, 158,  15,  81,   6,  13, 214,  38, 170,  37,\n",
       "        34, 157, 123,  86,  32,  33, 186, 122,  76,  99, 103, 118,  42,\n",
       "        41,  29,  24, 191, 204, 178, 155, 134,  36,  88, 224,  40,  63,\n",
       "        26, 210,  23,  28, 116, 105,  22, 135, 117,  30, 141,  94, 140,\n",
       "       120, 221, 100, 189,  73, 161,  87, 168, 243,  66, 213, 244, 112,\n",
       "       169,  92, 163, 222, 149,  75, 109, 165,  27, 160, 211, 136, 156,\n",
       "       179, 102, 218, 228, 219,   2, 217, 142, 176, 195, 111, 197,  39,\n",
       "       119, 201, 206, 114,  79,  69, 129, 126,  65, 162, 188, 177, 172,\n",
       "       152, 226, 150,   7, 127, 190, 199, 209,  31, 227, 124, 207, 185,\n",
       "       175,  61,  91, 182, 128, 131, 192,  89,  54, 225, 101, 180, 133,\n",
       "       205, 147, 151,  67,  70,  62,  84,  78, 208, 139, 187, 143,  97,\n",
       "        83, 144, 159,  96,  64,  90, 115, 194, 110, 184,  82, 174,  77,\n",
       "        80,  57, 107,  72, 220,  71, 229,  25, 145, 153, 171, 130,  95,\n",
       "       223, 212,  43, 148,  35,  93, 113, 108,  74,  56, 193, 245])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.argsort(np.array(model.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 246) (5000, 246)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(np.matmul(X_train.transpose(),X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(X_test)\n",
    "# Y_pred[np.where(Y_pred<0)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.108152718376441"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(Y_pred-Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353.675375922532"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Y_pred-Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.315979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.404966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.782817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>26.683395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.517039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.481832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.858342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.862650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>45.468669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.099469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.999344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.010228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>133.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.059114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.556365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-20.896779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39.0</td>\n",
       "      <td>49.854618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.799832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.542146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.660079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.975304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.750246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.255297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.0</td>\n",
       "      <td>23.675186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.281234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.967674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.999334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>3.0</td>\n",
       "      <td>127.344570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.821074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.077075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.891410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>442.0</td>\n",
       "      <td>166.368314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.779244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.388286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.495565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.255256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.559748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.313443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.817445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.286725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.534059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.175867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.383685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.109991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.515999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30.698406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>173.0</td>\n",
       "      <td>151.327902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.375131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>19.0</td>\n",
       "      <td>16.976870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.561515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.572764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual   Predicted\n",
       "0        0.0    0.963891\n",
       "1        0.0  -15.315979\n",
       "2        0.0   12.404966\n",
       "3        2.0   16.782817\n",
       "4        6.0   26.683395\n",
       "5        0.0    0.310330\n",
       "6        0.0    3.517039\n",
       "7        0.0   -3.481832\n",
       "8        0.0   -3.858342\n",
       "9        0.0   -4.862650\n",
       "10      10.0   45.468669\n",
       "11       2.0    0.099469\n",
       "12      11.0    8.999344\n",
       "13       0.0    1.679351\n",
       "14      15.0    2.010228\n",
       "15       0.0  133.563200\n",
       "16       4.0    0.059114\n",
       "17       0.0   -5.556365\n",
       "18       5.0  -20.896779\n",
       "19       1.0    0.260388\n",
       "20       0.0    0.637257\n",
       "21      39.0   49.854618\n",
       "22       0.0   -3.799832\n",
       "23       0.0   -1.542146\n",
       "24       0.0   13.660079\n",
       "25       0.0    1.975304\n",
       "26       4.0    9.750246\n",
       "27       0.0    3.255297\n",
       "28      30.0   23.675186\n",
       "29       0.0    0.657518\n",
       "...      ...         ...\n",
       "4970     0.0   -0.281234\n",
       "4971     0.0   -0.967674\n",
       "4972     0.0   -0.999334\n",
       "4973     0.0   -0.223478\n",
       "4974     3.0  127.344570\n",
       "4975     0.0   -1.821074\n",
       "4976     0.0    0.518857\n",
       "4977     0.0   -8.077075\n",
       "4978     0.0   -1.891410\n",
       "4979   442.0  166.368314\n",
       "4980     0.0   35.779244\n",
       "4981     0.0   12.388286\n",
       "4982     5.0    8.495565\n",
       "4983     0.0   -4.255256\n",
       "4984     0.0    8.559748\n",
       "4985     0.0    1.313443\n",
       "4986     0.0    1.817445\n",
       "4987     0.0   -1.286725\n",
       "4988     1.0   -1.534059\n",
       "4989     0.0   -0.413685\n",
       "4990     9.0   -6.175867\n",
       "4991     0.0   -2.383685\n",
       "4992     0.0   -3.109991\n",
       "4993     4.0    1.515999\n",
       "4994    10.0   30.698406\n",
       "4995   173.0  151.327902\n",
       "4996     0.0   -4.375131\n",
       "4997    19.0   16.976870\n",
       "4998     0.0   -2.561515\n",
       "4999     0.0   13.572764\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': Y_test.flatten(), 'Predicted': Y_pred.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = df[100:150]\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = df[100:150]\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = [ 1.1**x for x in range(-50,150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = [0,0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge()\n",
    "param = {'alpha':lamda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regressor  = GridSearchCV(rr, param,scoring=\"neg_mean_squared_error\" ,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3,\n",
       "                                   10, 30, 100, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1000, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1013.9681388173667"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
